{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(\\theta | x,y) &= \\frac{p(\\theta, y | x)}{p(y|x)} && (p(\\theta, y \\mid x) = p(\\theta \\mid x, y)p(y \\mid x)) \\\\\\\\\n",
    "&= \\frac{p(y | x, \\theta)p(\\theta | x)}{p(y | x)} && (p(\\theta, y \\mid x) = p(y \\mid x, \\theta)p(\\theta \\mid x)) \\\\\\\\\n",
    "&= \\frac{p(y | x, \\theta)p(\\theta)}{p(y | x)} && (\\text{since } p(\\theta) = p(\\theta | x) )  \\\\\\\\\n",
    "&= p(y | x, \\theta)p(\\theta) && ( \\text{since }  p(y|x) \\text{ is constant with respect to } \\theta ) \\\\\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Note:\n",
    "\n",
    "**\\*** [Why $P(\\theta, y | x) = P(\\theta | x, y)P(y | x)$](https://math.stackexchange.com/questions/4734021/why-p-theta-y-mid-x-p-theta-mid-x-ypy-mid-x)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "### i. prove\n",
    "\n",
    "Continue with (a)'s conclusion, to find MAP, we start we log-transformation :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta_{MAP} &= \\argmax_{\\theta} p(y | x, \\theta)p(\\theta) \\\\\\\\\n",
    "&= \\argmax_{\\theta} ( \\log p(y | x, \\theta) + \\log p(\\theta) + \\text{const}) \\\\\\\\\n",
    "&= \\argmin_{\\theta} ( -\\log p(y | x, \\theta) -\\log p(\\theta) ) \\\\\\\\\n",
    "&\\text{Let } \\lambda \\| \\theta \\|^2_2 = -\\log p(\\theta) \\text{ then,} \\\\\\\\\n",
    "&= \\argmin_{\\theta} ( -\\log p(y | x, \\theta)  + \\lambda \\| \\theta \\|^2_2 )\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Note:\n",
    "\n",
    "`argmin` and `argmax` are functions that return the argument that minimizes or maximizes a given function, respectively. To convert between the two, you can negate the function being optimized. Specifically, $\\argmin(f(x)) = \\argmax(-f(x))$. This is because negating a function flips its values, so the argument that minimizes the original function will maximize the negated function, and vice versa.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. What is value of $\\lambda$?\n",
    "\n",
    "From $\\mathcal{N}(0, \\eta^2 I)$ we can get normal distribution:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(\\theta) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The probability density function for a multivariate normal distribution with mean vector $\\mu$ and covariance matrix $\\Sigma$ is given by:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{(2\\pi)^k |\\Sigma|}} e^{-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)}\n",
    "$$\n",
    "\n",
    "where $k$ is the dimensionality of the distribution.\n",
    "\n",
    "The mean vector is 0, so we can simplify the above equation to:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{(2\\pi)^k |\\Sigma|}} e^{-\\frac{1}{2}x^T \\Sigma^{-1} x}\n",
    "$$\n",
    "\n",
    "The covariance matrix is given as $\\eta^2 I$, where $I$ is the identity matrix. The determinant of a diagonal matrix is the product of its diagonal elements, so $|\\eta^2 I| = (\\eta^2)^k$. The inverse of a diagonal matrix is another diagonal matrix with the reciprocal of the original diagonal elements, so $(\\eta^2 I)^{-1} = \\frac{1}{\\eta^2} I$. Substituting these values into the above equation, we get:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{(2\\pi)^k (\\eta^2)^k}} e^{-\\frac{1}{2}x^T \\left(\\frac{1}{\\eta^2} I\\right) x}\n",
    "$$\n",
    "\n",
    "Simplifying further, we get:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{(\\eta\\sqrt{2\\pi})^k} e^{-\\frac{1}{2\\eta^2}x^T x}\n",
    "$$\n",
    "\n",
    "So, if $\\theta$ follows a multivariate normal distribution with mean vector 0 and covariance matrix $\\eta^2 I$, then its probability density function is given by:\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\frac{1}{(\\eta\\sqrt{2\\pi})^k} \\exp({-\\frac{1}{2\\eta^2}\\theta^T \\theta})\n",
    "$$\n",
    "\n",
    "We can find some pattern now!\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\frac{1}{(\\eta\\sqrt{2\\pi})^k} \\exp({-\\frac{1}{2\\eta^2}\\theta^2})\n",
    "$$\n",
    "\n",
    "Then log $p(\\theta)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log p(\\theta) &= \\log \\left(\\frac{1}{(\\eta\\sqrt{2\\pi})^k} \\exp\\left({-\\frac{1}{2\\eta^2}\\theta^2}\\right)\\right) \\\\\n",
    "&= \\log \\left(\\frac{1}{(\\eta\\sqrt{2\\pi})^k}\\right) + \\log \\left(\\exp\\left({-\\frac{1}{2\\eta^2}\\theta^2}\\right)\\right) \\\\\n",
    "&= -k \\log (\\eta\\sqrt{2\\pi}) + \\left(-\\frac{1}{2\\eta^2}\\theta^2\\right) \\\\\n",
    "&= -k \\log (\\eta) - k \\log (\\sqrt{2\\pi}) - \\frac{1}{2\\eta^2}\\theta^2 \\\\\n",
    "&= -k \\log (\\eta) - \\frac{k}{2} \\log (2\\pi) - \\frac{1}{2\\eta^2}\\theta^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Because,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta_{MAP} &= \\argmin_{\\theta} ( -\\log p(y | x, \\theta)  - p(\\theta)) \\\\\\\\\n",
    "&=  \\argmin_{\\theta} ( -\\log p(y | x, \\theta)  + k \\log (\\eta) + \\frac{k}{2} \\log (2\\pi) + \\frac{1}{2\\eta^2}\\theta^2) \\\\\\\\\n",
    "&(\\text{remove the terms } k \\log (\\eta) + \\frac{k}{2} \\log (2\\pi) \\text{ from the expression because they are constants with respect to } \\theta )\\\\\\\\\n",
    "&= \\argmin_{\\theta} ( -\\log p(y | x, \\theta) + \\frac{1}{2\\eta^2}\\theta^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus we know $\\lambda = \\frac{1}{2\\eta^2}$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) closed expression\n",
    "\n",
    "Given:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\epsilon \\sim \\ \\mathcal{N}(0, \\sigma^2),\\\\\\\\\n",
    "&\\theta \\sim \\mathcal{N}(0, \\eta^2I), \\\\\\\\\n",
    "&\\text{And } y^{(i)} = \\theta^T x^{(i)} + \\epsilon^{(i)} \\\\\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let's consider the equation $y^{(i)} = \\theta^T x^{(i)} + \\epsilon^{(i)}$. This equation can be rewritten as:\n",
    "\n",
    "$$y^{(i)} = E[y^{(i)} | x^{(i)}, \\theta] + \\epsilon^{(i)}$$\n",
    "\n",
    "where $E[y^{(i)} | x^{(i)}, \\theta]$ represents the expected value of $y^{(i)}$ given $x^{(i)}$ and $\\theta$. Since $\\epsilon \\sim N(0, \\sigma^2)$, we have $E[\\epsilon] = 0$, so we can write:\n",
    "\n",
    "$$E[y^{(i)} | x^{(i)}, \\theta] = \\theta^T x^{(i)}$$\n",
    "\n",
    "This shows that the expected value of $y^{(i)}$ given $x^{(i)}$ and $\\theta$ is equal to $\\theta^T x^{(i)}$. Therefore, the conditional distribution of $y^{(i)}$ given $x^{(i)}$ and $\\theta$ is normal with mean $\\theta^T x^{(i)}$. Thus,\n",
    "\n",
    "$$y | x , \\theta \\sim \\mathcal{N}(\\theta^T x , \\sigma^2)$$\n",
    "\n",
    "then:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(y|x,θ) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - x_i^T\\theta)^2}{2\\sigma^2}\\right) \\\\\\\\\n",
    "&= \\frac{1}{(2\\pi)^{\\frac{m}{2}} \\sigma^m} \\exp(-\\frac{1}{2\\sigma^2} \\sum^m_{i=1} (y_i - \\theta^T x_i)^2 ) \\\\\\\\\n",
    "&\\text{Convert to represented by matrix } X \\text{ and } \\vec{y} \\text{ we have:} \\\\\\\\\n",
    "&= \\frac{1}{(2\\pi)^{\\frac{m}{2}} \\sigma^m} \\exp(-\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 ) \\\\\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then we do the $\\log$ for $p$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log(p(y|x,θ)) &= \\log\\left(\\frac{1}{(2\\pi)^{\\frac{m}{2}} \\sigma^m}\\right) + \\log\\left(\\exp(-\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 )\\right) \\\\\\\\\n",
    "&= -\\log((2\\pi)^{\\frac{m}{2}} \\sigma^m) + \\log\\left(\\exp(-\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 )\\right) \\\\\\\\\n",
    "&=  -(\\frac{m}{2}\\log(2\\pi) + m*\\log(\\sigma)) + \\log\\left(\\exp(-\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 )\\right) \\\\\\\\\n",
    "&= -(\\frac{m}{2}\\log(2\\pi) + m*\\log(\\sigma)) + (-\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 )\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate what could minimize the $\\theta$ !\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\theta_{MAP} &= \\argmin_{\\theta} ( -\\log p(y | x, \\theta) -\\log p(\\theta) ) \\\\\\\\\n",
    "&= \\argmin_{\\theta} \\left( \\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 +  \\frac{1}{2\\eta^2}\\theta^2 \\right) \\\\\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Find the derivative of the given equation with respect to $\\theta$, setting it to 0, and solving for $\\theta$:\n",
    "\n",
    "$$\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 +  \\frac{1}{2\\eta^2}\\theta^2  $$\n",
    "\n",
    "Take the derivative with respect to $\\theta$:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta} \\left(\\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 +  \\frac{1}{2\\eta^2}\\theta^2 \\right) = -\\frac{1}{\\sigma^2}X^T(\\vec{y}-X\\theta) + \\frac{\\theta}{\\eta^2}$$\n",
    "\n",
    "Set the derivative equal to 0 and solve for $\\theta$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&-\\frac{1}{\\sigma^2}X^T(\\vec{y}-X\\theta) + \\frac{\\theta}{\\eta^2} = 0 \\\\\\\\\n",
    "&\\Rightarrow -\\frac{1}{\\sigma^2}X^T\\vec{y}+\\frac{1}{\\sigma^2}X^TX\\theta + \\frac{\\theta}{\\eta^2} = 0 \\\\\\\\\n",
    "&\\Rightarrow -X^T\\vec{y} + X^TX\\theta + \\frac{\\theta \\sigma^2}{\\eta^2} = 0 \\\\\\\\\n",
    "&\\Rightarrow X^T\\vec{y} - X^TX\\theta - \\frac{\\theta \\sigma^2}{\\eta^2} = 0 \\\\\\\\\n",
    "&\\Rightarrow X^T\\vec{y} - ( X^TX + \\frac{\\sigma^2}{\\eta^2})  \\theta = 0 \\\\\\\\\n",
    "&\\Rightarrow X^T\\vec{y} = ( X^TX + \\frac{\\sigma^2}{\\eta^2}) \\theta  \\\\\\\\\n",
    "&\\Rightarrow( X^TX + \\frac{\\sigma^2}{\\eta^2})^{-1} X^T\\vec{y}  = \\theta   \\\\\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "\n",
    "From already known condition, we can induct such:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_L(\\theta | \\mu , b) &= \\frac{1}{2b} \\exp\\left( - \\frac{\\| \\theta \\|_1}{b} \\right) \\\\\\\\\n",
    "&\\text{Thus ,} \\\\\\\\\n",
    "\\Rightarrow p(\\theta) &= \\frac{1}{2b} \\exp\\left( - \\frac{\\| \\theta \\|_1}{b} \\right) \\\\\\\\\n",
    "\\Rightarrow \\log(p(\\theta)) &= 0 - \\log(2b) - \\frac{\\| \\theta \\|}{b} = - \\log(2b) - \\frac{\\| \\theta \\|_1}{b} \\\\\\\\\n",
    "\\Rightarrow \\theta_{MAP} &= \\argmin_{\\theta} ( -\\log p(y | x, \\theta) -\\log p(\\theta) ) \\\\\\\\\n",
    "&= \\argmin_{\\theta} \\left( \\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 +  \\frac{\\| \\theta \\|_1}{b} \\right) \\\\\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "`argmin_{theta}` is used to find the value of `theta` that minimizes the function `J(theta)`. This means that we are trying to find the optimal value of `theta` that results in the smallest possible value of `J(theta)`.\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta} J(\\theta)\n",
    "$$\n",
    "\n",
    "Then we can get this:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\theta) &= \\left( \\frac{1}{2\\sigma^2} (\\vec{y} - X\\theta )^2 +  \\frac{\\| \\theta \\|_1}{b} \\right) \\\\\\\\\n",
    "&= \\left( (\\vec{y} - X\\theta )^2 +  \\frac{2\\sigma^2 }{b} \\| \\theta \\|_1 \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, $\\gamma =\\frac{2\\sigma^2 }{b} $\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lake-influx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
