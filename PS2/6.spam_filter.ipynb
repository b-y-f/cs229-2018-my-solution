{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import src.util as util\n",
    "import src.svm as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages, train_labels = util.load_spam_dataset(\"./data/ds6_train.tsv\")\n",
    "val_messages, val_labels = util.load_spam_dataset(\"./data/ds6_val.tsv\")\n",
    "test_messages, test_labels = util.load_spam_dataset(\"./data/ds6_test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) pre-process message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(message):\n",
    "    \"\"\"Get the normalized list of words from a message string.\n",
    "\n",
    "    This function should split a message into words, normalize them, and return\n",
    "    the resulting list. For splitting, you should split on spaces. For normalization,\n",
    "    you should convert everything to lowercase.\n",
    "\n",
    "    Args:\n",
    "        message: A string containing an SMS message\n",
    "\n",
    "    Returns:\n",
    "       The list of normalized words from the message.\n",
    "    \"\"\"\n",
    "\n",
    "    # *** START CODE HERE ***\n",
    "    return message.lower().split(\" \")\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def create_dictionary(messages):\n",
    "    \"\"\"Create a dictionary mapping words to integer indices.\n",
    "\n",
    "    This function should create a dictionary of word to indices using the provided\n",
    "    training messages. Use get_words to process each message.\n",
    "\n",
    "    Rare words are often not useful for modeling. Please only add words to the dictionary\n",
    "    if they occur in at least five messages.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings containing SMS messages\n",
    "\n",
    "    Returns:\n",
    "        A python dict mapping words to integers.\n",
    "    \"\"\"\n",
    "\n",
    "    # *** START CODE HERE ***\n",
    "    word_dict = defaultdict(int)\n",
    "    for message in messages:\n",
    "        for word in get_words(message):\n",
    "            word_dict[word] += 1\n",
    "\n",
    "    word_dict = {\n",
    "        word: index\n",
    "        for index, word in enumerate(\n",
    "            word for word, count in word_dict.items() if count >= 5\n",
    "        )\n",
    "    }\n",
    "    return word_dict\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def transform_text(messages, word_dictionary):\n",
    "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
    "\n",
    "    This function should create a numpy array that contains the number of times each word\n",
    "    appears in each message. Each row in the resulting array should correspond to each\n",
    "    message and each column should correspond to a word.\n",
    "\n",
    "    Use the provided word dictionary to map words to column indices. Ignore words that\n",
    "    are not present in the dictionary. Use get_words to get the words for a message.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings where each string is an SMS message.\n",
    "        word_dictionary: A python dict mapping words to integers.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array marking the words present in each message.\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    result = np.zeros((len(messages), len(word_dictionary)))\n",
    "    for i, message in enumerate(messages):\n",
    "        word_counts = Counter(get_words(message))\n",
    "        for word, count in word_counts.items():\n",
    "            if word in word_dictionary:\n",
    "                result[i, word_dictionary[word]] = count\n",
    "    return result\n",
    "    # *** END CODE HERE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = create_dictionary(train_messages)\n",
    "train_matrix = transform_text(train_messages, dictionary)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_naive_bayes_model(matrix, labels, k=1):\n",
    "    \"\"\"Fit a naive bayes model.\n",
    "    Note: ham = 0 , spam = 1\n",
    "\n",
    "    This function should fit a Naive Bayes model given a training matrix and labels.\n",
    "\n",
    "    The function should return the state of that model.\n",
    "\n",
    "    Feel free to use whatever datatype you wish for the state of the model.\n",
    "\n",
    "    Args:\n",
    "        matrix: A numpy array containing word counts for the training data\n",
    "        labels: The binary (0 or 1) labels for that training data\n",
    "\n",
    "    Returns: The trained model\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    prior_ham = np.mean(labels == 0)\n",
    "    prior_spam = np.mean(labels == 1)\n",
    "\n",
    "    model = {\"prior_ham\": np.log(prior_ham), \"prior_spam\": np.log(prior_spam)}\n",
    "\n",
    "    ham_messages = matrix[labels == 0]\n",
    "    spam_messages = matrix[labels == 1]\n",
    "\n",
    "    total_ham_word = np.sum(ham_messages)\n",
    "    total_spam_word = np.sum(spam_messages)\n",
    "\n",
    "    V = matrix.shape[1]\n",
    "\n",
    "    # laplace smoothing\n",
    "    model[\"ham_probs\"] = (ham_messages.sum(axis=0) + k) / (total_ham_word + k * V)\n",
    "    model[\"spam_probs\"] = (spam_messages.sum(axis=0) + k) / (total_spam_word + k * V)\n",
    "\n",
    "    return model\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def predict_from_naive_bayes_model(model, matrix):\n",
    "    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n",
    "\n",
    "    This function should be able to predict on the models that fit_naive_bayes_model\n",
    "    outputs.\n",
    "\n",
    "    Args:\n",
    "        model: A trained model from fit_naive_bayes_model\n",
    "        matrix: A numpy array containing word counts\n",
    "\n",
    "    Returns: A numpy array containg the predictions from the model\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    ham_probs_log = np.log(model[\"ham_probs\"])\n",
    "    spam_probs_log = np.log(model[\"spam_probs\"])\n",
    "\n",
    "    ham_scores = matrix.dot(ham_probs_log) + model[\"prior_ham\"]\n",
    "    spam_scores = matrix.dot(spam_probs_log) + model[\"prior_spam\"]\n",
    "\n",
    "    return (ham_scores < spam_scores).astype(int)\n",
    "    # *** END CODE HERE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.9802867383512545\n",
      "validation accuracy:  0.9820466786355476\n"
     ]
    }
   ],
   "source": [
    "val_matrix = transform_text(val_messages, dictionary)\n",
    "test_matrix = transform_text(test_messages, dictionary)\n",
    "\n",
    "naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels, k=5)\n",
    "\n",
    "naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n",
    "naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n",
    "print(\"test accuracy: \", naive_bayes_accuracy)\n",
    "\n",
    "naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, val_matrix)\n",
    "naive_bayes_accuracy = np.mean(naive_bayes_predictions == val_labels)\n",
    "print(\"validation accuracy: \", naive_bayes_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('claim', 3.8572617067628734), ('won', 3.291947897712813), ('prize', 3.2717451903952934), ('now!', 3.1705870407085452), ('tone', 3.017511052011053)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_five_naive_bayes_words(model, dictionary):\n",
    "    \"\"\"Compute the top five words that are most indicative of the spam (i.e positive) class.\n",
    "\n",
    "    Ues the metric given in 6c as a measure of how indicative a word is.\n",
    "    Return the words in sorted form, with the most indicative word first.\n",
    "\n",
    "    Args:\n",
    "        model: The Naive Bayes model returned from fit_naive_bayes_model\n",
    "        dictionary: A mapping of word to integer ids\n",
    "\n",
    "    Returns: The top five most indicative words in sorted order with the most indicative first\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    token_given_ham = model[\"ham_probs\"]\n",
    "    token_given_spam = model[\"spam_probs\"]\n",
    "    token_scores = np.log(token_given_spam) - np.log(token_given_ham)\n",
    "    top_5_indices = token_scores.argsort()[-5:][::-1]\n",
    "\n",
    "    top_5_words = [\n",
    "        (k, token_scores[v]) for k, v in dictionary.items() if v in top_5_indices\n",
    "    ]\n",
    "    sorted_top_5_words = sorted(top_5_words, key=lambda x: -x[1])\n",
    "    print(sorted_top_5_words)\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "get_top_five_naive_bayes_words(naive_bayes_model, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_svm_radius(\n",
    "    train_matrix, train_labels, val_matrix, val_labels, radius_to_consider\n",
    "):\n",
    "    \"\"\"Compute the optimal SVM radius using the provided training and evaluation datasets.\n",
    "\n",
    "    You should only consider radius values within the radius_to_consider list.\n",
    "    You should use accuracy as a metric for comparing the different radius values.\n",
    "\n",
    "    Args:\n",
    "        train_matrix: The word counts for the training data\n",
    "        train_labels: The spma or not spam labels for the training data\n",
    "        val_matrix: The word counts for the validation data\n",
    "        val_labels: The spam or not spam labels for the validation data\n",
    "        radius_to_consider: The radius values to consider\n",
    "\n",
    "    Returns:\n",
    "        The best radius which maximizes SVM accuracy.\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    res = []\n",
    "    for rad in radius_to_consider:\n",
    "        svm_predictions = svm.train_and_predict_svm(\n",
    "            train_matrix, train_labels, val_matrix, rad\n",
    "        )\n",
    "        res.append((rad, np.mean(svm_predictions == val_labels)))\n",
    "\n",
    "    optimal_radius = sorted(res, key=lambda x: -x[1])\n",
    "    return optimal_radius[0][0]\n",
    "    # *** END CODE HERE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal SVM radius was 0.1\n",
      "The SVM model had an accuracy of 0.9713261648745519 on the testing set\n"
     ]
    }
   ],
   "source": [
    "optimal_radius = compute_best_svm_radius(\n",
    "    train_matrix, train_labels, val_matrix, val_labels, [0.01, 0.1, 1, 10]\n",
    ")\n",
    "print(\"The optimal SVM radius was {}\".format(optimal_radius))\n",
    "\n",
    "svm_predictions = svm.train_and_predict_svm(\n",
    "    train_matrix, train_labels, test_matrix, optimal_radius\n",
    ")\n",
    "\n",
    "svm_accuracy = np.mean(svm_predictions == test_labels)\n",
    "\n",
    "print(\n",
    "    \"The SVM model had an accuracy of {} on the testing set\".format(\n",
    "        svm_accuracy, optimal_radius\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lake-influx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
